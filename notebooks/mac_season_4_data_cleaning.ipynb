{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation for Input Trait Data\n",
    "\n",
    "LeBauer, David et al. (2020), Data From: TERRA-REF, An open reference data set from high resolution genomics, phenomics, and imaging sensors, v6, Dryad, Dataset, https://doi.org/10.5061/dryad.4b8gtht99\n",
    "\n",
    "##### Environmental weather data \n",
    "- downloaded from the MAC weather station [website](https://cals.arizona.edu/azmet/06.htm)\n",
    "- cleaned using the code in the `season_4_weather_data_cleaning` notebook in this repository\n",
    "\n",
    "Please email ejcain@arizona.edu with any questions or comments or create an issue in this [repository](https://github.com/MagicMilly/for-data-publication) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "### I. Import Python packages\n",
    "\n",
    "### II. Functions Used\n",
    "\n",
    "### III. Read in Datasets for cleaning\n",
    "  - Aboveground Dry Biomass\n",
    "  - Canopy Height - Sensor\n",
    "  - Canopy Height - Manual\n",
    "  - Days & GDD to Flowering\n",
    "  - Days & GDD to Flag Leaf Emergence\n",
    "\n",
    "### IV. Save Derived Datasets to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAC Season 4 Data Cleaning\n",
    "\n",
    "#### Traits\n",
    "- aboveground dry biomass\n",
    "- canopy height\n",
    "- days & growing degree days (GDD) to flowering\n",
    "- days & GDD to flag leaf emergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Import Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(df, value_column, trait_column):\n",
    "    \n",
    "    trait_name = df[trait_column].unique()[0]\n",
    "    return df[value_column].hist(color='navy').set_xlabel(trait_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_nulls_duplicates(df):\n",
    "    \n",
    "    print(\n",
    "        f'Sum of null values:\\n{df.isnull().sum()}\\n-----\\n'\n",
    "        f'Value counts for duplicates:\\n{df.duplicated().value_counts()}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique_values(df):\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique() < 5:\n",
    "            print(f'{df[col].nunique()} unique value(s) for {col} column: {df[col].unique()}')    \n",
    "        else:\n",
    "            print(f'{df[col].nunique()} values for {col} column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_range_column_values(working_df, plot_column):\n",
    "    \n",
    "    new_df = working_df.copy()\n",
    "    new_df['range'] = new_df[plot_column].str.extract(\"Range (\\d+)\").astype(int)\n",
    "    new_df['column'] = new_df[plot_column].str.extract(\"Column (\\d+)\").astype(int)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime_column(working_df, date_column):\n",
    "    \n",
    "    new_datetimes = pd.to_datetime(working_df[date_column])\n",
    "    new_df_0 = working_df.drop(labels=date_column, axis=1)\n",
    "    new_df_1 = new_df_0.copy()\n",
    "    new_df_1['date'] = new_datetimes\n",
    "    \n",
    "    return new_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_value_column(working_df, value_column, trait_column):\n",
    "    \n",
    "    trait = working_df[trait_column].unique()[0]\n",
    "    new_df_0 = working_df.rename({value_column: trait}, axis=1)\n",
    "    new_df_1 = new_df_0.drop(labels=trait_column, axis=1)\n",
    "    \n",
    "    return new_df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blocking height experiment description for season 4 can be found [here](https://terraref.ncsa.illinois.edu/bety/api/v1/experiments?name=~MAC+Season+4:+All+BAP+With+Late+Season+Drought)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_season_4_blocking_height(working_df, range_column):\n",
    "    \n",
    "    short_blocks = [11, 20, 46, 50]\n",
    "    medium_blocks = [10, 12, 18, 24, 27, 29, 31, 33, 38, 51]\n",
    "    tall_blocks = [3, 4, 5, 6, 7, 8, 9, 13, 14, 15, 16, 17, 19, 21, 22, 23, 25, 26, 28, 30, 32, 34, 35, 36, 37, \n",
    "                   39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 52]\n",
    "    border = [1, 2, 53, 54]\n",
    "    \n",
    "    range_values = working_df[range_column].values\n",
    "    blocking_heights = []\n",
    "    \n",
    "    for r in range_values:\n",
    "        \n",
    "        if r in short_blocks:\n",
    "            blocking_heights.append('short')\n",
    "            \n",
    "        elif r in medium_blocks:\n",
    "            blocking_heights.append('medium')\n",
    "            \n",
    "        elif r in tall_blocks:\n",
    "            blocking_heights.append('tall')\n",
    "            \n",
    "        elif r in border:\n",
    "            blocking_heights.append('border')\n",
    "            \n",
    "        else:\n",
    "            print(f'Error with range value {r}')\n",
    "        \n",
    "    working_df_1 = working_df.copy()\n",
    "    working_df_1['blocking_height'] = blocking_heights\n",
    "    \n",
    "    return working_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_columns(working_df, new_col_order_list):\n",
    "    \n",
    "    working_df_1 = pd.DataFrame(data=working_df, columns=new_col_order_list)\n",
    "    return working_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_subplots(df, plot_col):\n",
    "\n",
    "    for name in df[plot_col].values:\n",
    "        if (name.endswith(' E')) | (name.endswith(' W')):\n",
    "             return 'This dataset contains subplot designations'\n",
    "        else:\n",
    "            return 'No subplot designations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_subplots(working_df, plot_col, new_plot_col_name):\n",
    "    \n",
    "    plot_names = working_df[plot_col].values\n",
    "    new_plot_names = []\n",
    "    \n",
    "    for n in plot_names:\n",
    "        if (n.endswith(' E') | (n.endswith(' W'))):\n",
    "            new_plot_names.append(n[:-2])    \n",
    "        else:\n",
    "            new_plot_names.append(n)\n",
    "            \n",
    "    working_df_1 = working_df.drop(labels=plot_col, axis=1)\n",
    "    working_df_2 = working_df_1.copy()\n",
    "    \n",
    "    working_df_2[new_plot_col_name] = new_plot_names\n",
    "    return working_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv_with_timestamp(df, name_of_dataset):\n",
    "    \n",
    "    timestamp = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "    output_filename = ('data/processed/' + f'{name_of_dataset}_' + f'{timestamp}.csv').replace(':', '')\n",
    "\n",
    "    df.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv_without_timestamp(list_of_dfs, list_of_output_filenames):\n",
    "\n",
    "    for i,j in zip(list_of_dfs, list_of_output_filenames):\n",
    "        i.to_csv(j, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Read in datasets\n",
    "- Season four trait data can be downloaded from Dryad https://doi.org/10.5061/dryad.4b8gtht99\n",
    "- Each trait - separated by method, if applicable - can be found in its own `.csv` file\n",
    "- Changes applied to all datasets\n",
    "    - Extract `range` and `column` values to add to dataframe\n",
    "    - Convert string date column values to datetime objects\n",
    "    - Rename values column (usually `mean`) to the trait being measured\n",
    "    - Add `blocking_height` column\n",
    "- Columns dropped from all datasets\n",
    "    - `checked` \n",
    "    - `author`\n",
    "    - `season`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Aboveground Dry Biomass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_0 = pd.read_csv('data/raw/season_4_traits/season_4_aboveground_dry_biomass_manual.csv')\n",
    "print(adb_0.shape)\n",
    "# adb_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(adb_0, 'mean', 'trait')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_nulls_duplicates(adb_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_unique_values(adb_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_1 = extract_range_column_values(adb_0, 'plot')\n",
    "print(adb_1.shape)\n",
    "# adb_1.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_2 = convert_datetime_column(adb_1, 'date')\n",
    "print(adb_2.shape)\n",
    "# adb_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_3 = rename_value_column(adb_2, 'mean', 'trait')\n",
    "print(adb_3.shape)\n",
    "# adb_3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['checked', 'author', 'season']\n",
    "\n",
    "adb_4 = adb_3.drop(labels=cols_to_drop, axis=1)\n",
    "print(adb_4.shape)\n",
    "# adb_4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_5 = add_season_4_blocking_height(adb_4, 'range')\n",
    "print(adb_5.shape)\n",
    "# adb_5.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add units (kg/ha) column to aboveground dry biomass dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_6 = adb_5.copy()\n",
    "adb_6['units'] = 'kg/ha'\n",
    "\n",
    "print(adb_6.shape)\n",
    "# adb_6.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_order = ['date', 'plot', 'range', 'column', 'scientificname', 'genotype', 'treatment', 'blocking_height', \n",
    "                 'method', 'aboveground_dry_biomass', 'units', 'method_type']\n",
    "\n",
    "adb_7 = reorder_columns(adb_6, new_col_order)\n",
    "print(adb_7.shape)\n",
    "adb_7.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Canopy Height - Sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_0 = pd.read_csv('data/raw/season_4_traits/season_4_canopy_height_sensor.csv')\n",
    "print(ch_0.shape)\n",
    "# ch_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_unique_values(ch_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_nulls_duplicates(ch_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_1 = ch_0.drop_duplicates(ignore_index=True)\n",
    "print(ch_1.shape)\n",
    "check_for_nulls_duplicates(ch_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_subplots(ch_1, 'plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_2 = extract_range_column_values(ch_1, 'plot')\n",
    "print(ch_2.shape)\n",
    "# ch_2.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_3 = convert_datetime_column(ch_2, 'date')\n",
    "print(ch_3.shape)\n",
    "# ch_3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_4 = rename_value_column(ch_3, 'mean', 'trait')\n",
    "print(ch_4.shape)\n",
    "# ch_4.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_5 = add_season_4_blocking_height(ch_4, 'range')\n",
    "# ch_5.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_6 = ch_5.drop(labels=['checked', 'author', 'season'], axis=1)\n",
    "print(ch_6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add units column\n",
    "- cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_7 = ch_6.copy()\n",
    "ch_7['units'] = 'cm'\n",
    "print(ch_7.shape)\n",
    "# ch_7.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_order = ['date', 'plot', 'range', 'column', 'scientificname', 'genotype', 'treatment', 'blocking_height', \n",
    "                 'method', 'canopy_height', 'units', 'method_type']\n",
    "\n",
    "ch_8 = reorder_columns(ch_7, new_col_order)\n",
    "print(ch_8.shape)\n",
    "ch_8.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Canopy Height - Manual\n",
    "- using SQLite for `groupby`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chm_0 = pd.read_csv('data/raw/season_4_traits/season_4_canopy_height_manual.csv')\n",
    "print(chm_0.shape)\n",
    "# chm_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_nulls_duplicates(chm_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_unique_values(chm_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chm_1 = extract_range_column_values(chm_0, 'plot')\n",
    "print(chm_1.shape)\n",
    "# chm_1.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chm_2 = convert_datetime_column(chm_1, 'date')\n",
    "print(chm_2.shape)\n",
    "# chm_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify and Remove Subplot Designations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_subplots(chm_2, 'plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chm_3 = strip_subplots(chm_2, 'plot', 'plot')\n",
    "print(chm_3.shape)\n",
    "# chm_3.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_subplots(chm_3, 'plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for plot/date/mean/treatment duplicates\n",
    "\n",
    "chm_3.duplicated(subset=['plot', 'date', 'mean', 'treatment']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates\n",
    "\n",
    "chm_4 = chm_3.drop_duplicates(ignore_index=True, subset=['plot', 'genotype', 'treatment', 'mean', 'range', 'column',\n",
    "                                                        'date'])\n",
    "\n",
    "print(chm_4.shape)\n",
    "chm_4.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chm_5 = add_season_4_blocking_height(chm_4, 'range')\n",
    "print(chm_5.shape)\n",
    "# chm_5.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use sqlite database to group by `plot`, `date`, and `mean` \n",
    "- rename `mean` to `canopy_height_cm`\n",
    "- can also drop and reorder columns at this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data/interim/canopy_heights_manual_season_4.sqlite')\n",
    "cursor = conn.cursor()\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment next line out if db has already been created\n",
    "chm_5.to_sql('canopy_heights_manual_season_4.sqlite', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chm_6 = pd.read_sql_query(\"\"\"\n",
    "                            SELECT date, plot, range, column, scientificname, genotype, treatment, blocking_height,\n",
    "                            method, ROUND(AVG([mean]), 2) AS canopy_height_cm, method_type\n",
    "                            FROM 'canopy_heights_manual_season_4.sqlite'\n",
    "                            GROUP BY plot, date,[mean]\n",
    "                            ORDER BY date ASC;\n",
    "                            \"\"\", conn)\n",
    "\n",
    "print(chm_6.shape)\n",
    "chm_6.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Days & GDD to Flowering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_0 = pd.read_csv('data/raw/season_4_traits/season_4_flowering_time_manual.csv')\n",
    "print(fl_0.shape)\n",
    "# fl_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in updated processed weather dataset for season 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_0 = pd.read_csv('data/processed/mac_season_4_daily_weather_2020-07-01T144735.csv')\n",
    "print(weather_0.shape)\n",
    "# weather_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(fl_0, 'mean', 'trait')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_nulls_duplicates(fl_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_subplots(fl_0, 'plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_unique_values(fl_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add planting date 2017-04-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_planting = datetime.date(2017,4,20)\n",
    "flower_df_1 = fl_0.copy()\n",
    "\n",
    "flower_df_1['date_of_planting'] = day_of_planting\n",
    "print(flower_df_1.shape)\n",
    "# flower_df_1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create datetime with days to flowering (`mean`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta = pd.Series([pd.Timedelta(days=i) for i in flower_df_1['mean'].values])\n",
    "dates_of_flowering = []\n",
    "\n",
    "for td in timedelta:\n",
    "    \n",
    "    date_of_flowering = day_of_planting + td\n",
    "    dates_of_flowering.append(date_of_flowering)\n",
    "    \n",
    "print(flower_df_1.shape[0])\n",
    "print(len(dates_of_flowering))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_df_2 = flower_df_1.copy()\n",
    "flower_df_2['date_of_flowering'] = dates_of_flowering\n",
    "print(flower_df_2.shape)\n",
    "# flower_df_2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add GDD to flowering dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice weather df for date and cumulative gdd values only\n",
    "\n",
    "season_4_gdd = weather_0[['date', 'gdd']]\n",
    "print(season_4_gdd.shape)\n",
    "# season_4_gdd.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_4_gdd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_df_3 = flower_df_2.copy()\n",
    "flower_df_3.date_of_flowering = pd.to_datetime(flower_df_3.date_of_flowering)\n",
    "# flower_df_3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_4_gdd_1 = season_4_gdd.copy()\n",
    "season_4_gdd_1['date'] = pd.to_datetime(season_4_gdd_1['date'])\n",
    "season_4_gdd_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_df_4 = flower_df_3.merge(season_4_gdd_1, how='left', left_on='date_of_flowering', right_on='date')\n",
    "print(flower_df_4.shape)\n",
    "# flower_df_4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_df_5 = extract_range_column_values(flower_df_4, 'plot')\n",
    "flower_df_6 = add_season_4_blocking_height(flower_df_5, 'range')\n",
    "\n",
    "print(flower_df_6.shape)\n",
    "# flower_df_6.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_df_7 = rename_value_column(flower_df_6, 'mean', 'trait')\n",
    "# flower_df_7.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_df_8 = flower_df_7.rename({'flowering_time': 'days_to_flowering', 'gdd': 'gdd_to_flowering'}, axis=1)\n",
    "# flower_df_8.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['date_x', 'checked', 'author', 'season', 'date_of_planting', 'date_y']\n",
    "\n",
    "flower_df_9 = flower_df_8.drop(labels=cols_to_drop, axis=1)\n",
    "print(flower_df_9.shape)\n",
    "# flower_df_9.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_order = ['plot', 'range', 'column', 'scientificname', 'genotype', 'treatment', 'blocking_height', \n",
    "                 'method', 'date_of_flowering', 'days_to_flowering', 'gdd_to_flowering', 'method_type']\n",
    "\n",
    "flower_df_10 = reorder_columns(flower_df_9, new_col_order)\n",
    "print(flower_df_10.shape)\n",
    "flower_df_10.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Days & GDD to Flag Leaf Emergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fle_0 = pd.read_csv('data/raw/season_4_traits/season_4_flag_leaf_emergence_time_manual.csv')\n",
    "print(fle_0.shape)\n",
    "# fle_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in updated processed weather dataset for season 4\n",
    "Code used to process weather data for season 4 can be found in the `season_4_weather_data_cleaning` notebook in this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_0 = pd.read_csv('data/processed/mac_season_4_daily_weather_2020-07-01T144735.csv')\n",
    "print(weather_0.shape)\n",
    "# weather_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(fle_0, 'mean', 'trait')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_nulls_duplicates(fle_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_subplots(fle_0, 'plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_unique_values(fle_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add planting date 2017-04-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_planting = datetime.date(2017,4,20)\n",
    "fle_df_1 = fle_0.copy()\n",
    "\n",
    "fle_df_1['date_of_planting'] = day_of_planting\n",
    "print(fle_df_1.shape)\n",
    "# fle_df_1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create timedelta using days to flag leaf emergence (`mean`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta = pd.Series([pd.Timedelta(days=i) for i in fle_df_1['mean'].values])\n",
    "dates_of_flag_leaf_emergence = []\n",
    "\n",
    "for td in timedelta:\n",
    "    \n",
    "    date_of_flag_leaf_emergence = day_of_planting + td\n",
    "    dates_of_flag_leaf_emergence.append(date_of_flag_leaf_emergence)\n",
    "    \n",
    "print(fle_df_1.shape[0])\n",
    "print(len(dates_of_flag_leaf_emergence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fle_df_2 = fle_df_1.copy()\n",
    "fle_df_2['date_of_flag_leaf_emergence'] = dates_of_flag_leaf_emergence\n",
    "print(fle_df_2.shape)\n",
    "# fle_df_2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add GDD values to flag leaf emergence dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice weather df for date and cumulative gdd values only\n",
    "\n",
    "season_4_gdd = weather_0[['date', 'gdd']]\n",
    "print(season_4_gdd.shape)\n",
    "# season_4_gdd.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fle_df_3 = fle_df_2.copy()\n",
    "fle_df_3.date_of_flag_leaf_emergence = pd.to_datetime(fle_df_3.date_of_flag_leaf_emergence)\n",
    "# fle_df_3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_4_gdd_1 = season_4_gdd.copy()\n",
    "season_4_gdd_1['date'] = pd.to_datetime(season_4_gdd_1['date'])\n",
    "season_4_gdd_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fle_df_4 = fle_df_3.merge(season_4_gdd_1, how='left', left_on='date_of_flag_leaf_emergence', right_on='date')\n",
    "print(fle_df_4.shape)\n",
    "# fle_df_4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fle_df_5 = extract_range_column_values(fle_df_4, 'plot')\n",
    "fle_df_6 = add_season_4_blocking_height(fle_df_5, 'range')\n",
    "\n",
    "print(fle_df_6.shape)\n",
    "# fle_df_6.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fle_df_7 = rename_value_column(fle_df_6, 'mean', 'trait')\n",
    "# fle_df_7.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fle_df_8 = fle_df_7.rename({'flag_leaf_emergence_time': 'days_to_flag_leaf_emergence', 'gdd': 'gdd_to_flag_leaf_emergence'}, axis=1)\n",
    "# fle_df_8.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['date_x', 'checked', 'author', 'season', 'date_of_planting', 'date_y']\n",
    "\n",
    "fle_df_9 = fle_df_8.drop(labels=cols_to_drop, axis=1)\n",
    "print(fle_df_9.shape)\n",
    "# fle_df_9.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_order = ['plot', 'range', 'column', 'scientificname', 'genotype', 'treatment', 'blocking_height', \n",
    "                 'method', 'date_of_flag_leaf_emergence', 'days_to_flag_leaf_emergence', \n",
    "                 'gdd_to_flag_leaf_emergence', 'method_type']\n",
    "\n",
    "fle_df_10 = reorder_columns(fle_df_9, new_col_order)\n",
    "print(fle_df_10.shape)\n",
    "fle_df_10.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all datasets to separate csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = [adb_7, ch_8, chm_6, flower_df_10, fle_df_10]\n",
    "list_of_output_filenames = ['data/processed/mac_season_4_aboveground_dry_biomass.csv',\n",
    "                           'data/processed/mac_season_4_canopy_height_sensor.csv',\n",
    "                           'data/processed/mac_season_4_canopy_height_manual.csv',\n",
    "                           'data/processed/mac_season_4_days_gdd_to_flowering.csv',\n",
    "                           'data/processed/mac_season_4_days_gdd_to_flag_leaf_emergence.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv_without_timestamp(list_of_dfs, list_of_output_filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
